Photo by Chris Rhoads on Unsplash A crisis such as the Covid-19 pandemic creates a perfect opportunity for those who wish to cause confusion, chaos and public harm. Mis- and disinformation enables them to do just that. This week we look at another element that often works to facilitate disinformation: echo chambers. Through the Real411 platform, Media Monitoring Africa has been tracking disinformation trends on digital platforms since the end of March. Using the Real411 platform, we have analysed disinformation trends which have largely focused on Covid-19. To date, the platform has received 733 complaints, of which 710 have been assessed and action taken. Of the complaints about disinformation (555), 45% have been found to be disinformation. Over the last several weeks, we have looked at selected examples and trends. In this piece we look at some of the factors that make disinformation both easy and challenging to identify and combat, and at another element that often works to facilitate disinformation: echo chambers. What we know about disinformation First, one of the core ways of spotting disinformation is to look at the emotional triggers. Content that pushes your buttons, makes you feel really angry, afraid or anxious is likely to be disinformation. Another aspect of disinformation is that it contains elements of truth. If it doesn’t resonate at all in any way, people won’t believe it. One of the central elements of disinformation is that it tends to offer simple solutions to complex problems. Covid-19 is ripe for disinformation because not that much is known about it. It has also generated high levels of anxiety, so when people started to offer seemingly irrational causes for it, they weren’t laughed out of town. So, rather than making us process complex theories about what is happening and what the best way of dealing with it is, disinformation offers us easy answers that hint at things we aren’t meant to know. The idea we aren’t meant to know about these things ironically helps us feel better that we don’t really understand what is going on. The notion that actually it is all part of a conspiracy by mobile operators or government/Bill Gates to control us – while patently silly on a rational level – offers a simple answer and can help us regain a sense of grasping what’s going on and having a measure of control. As we have started to emerge from the first wave of Covid-19, we have seen how the attention of the disinformers is also shifting back to well-trodden grounds: around xenophobia, around the parlous state of our economy and many other elements. Jobs are scarce, the economy is stalled, and there are high crime levels and rising poverty. These are all real and massive challenges. Disinformers see the opportunity. They take these issues and our fears, anxieties and anger around them and, rather than offering nuanced understanding or a fuller picture, they might say something like: “Foreigners, and Nigerians in particular, are taking our jobs and women. #PutSouthAfricansFirst.” Instead of looking at issues of immigration, how non-citizens help build our nation, or helping to understand our economy and why there are so many job losses, the disinformer creates an easy scapegoat – “Nigerians”. Yes, some Nigerians are involved in crime, drug dealing and cheap labour, but so too is just about every single nationality on Earth. The idea that a citizenship confers illegality by virtue of where someone was born is ridiculous and fundamentally racist. The hook is created as a simple cause and then an equally obvious solution is often offered, such as: “Send them all back to where they came from.” The moment these ideas are tested or analysed, they simply cannot hold. It’s one reason only 50 people showed up to protest against Nigerians at the Nigerian embassy recently. But, let’s be clear. That 50 people showed up shows how dangerous this kind of logic and speech really are. It also highlights how words matter, and how perpetuating hate and disinformation causes real harm. At this point, you might be saying, “Well yes, but I see this for the rubbish it is and I won’t fall for it.” We say, not so fast! Precisely because, if it was just a few random racist or sexist messages, they more than likely wouldn’t take hold. Some other key elements help make them a lot more powerful. This is where it is useful to remember how social media platforms work. At any one time there are vast numbers of posts and content uploaded to the platforms. About 6,000 tweets every second and on Facebook around 350 million photos are uploaded every day. There is simply no way anyone can see all of it, so these platforms use your data and algorithms to predict and help determine what you are exposed to. In other words, because of the massive amounts of data they have on you, they use automated decision-making in their systems to filter content they think you want to see, that you then get on your device. To a large degree, this isn’t anything new: editors of news media make similar decisions on our behalf. Each day they decide what kind of news stories we should see and which ones will be left out. The difference, of course, is that in news media there are real people who take these decisions – and we can critique how they take them and the biases implicit in the stories they choose – but with social media, the decisions are taken by machines.  There are two big issues here. The first is that some assume that just because decisions are taken by machines, they have no biases. But, in reality, automated decision-making or algorithms, because they are built by people, often have the same biases and stereotypes as those who write them. Indeed, we have seen a number of examples over the past few years that have highlighted how algorithms are frequently imbued with race and gender stereotypes. Twitter, for example, made the news recently as one of its algorithms was exposed for selecting white people over black people. So, just because machines choose for us doesn’t mean the choices aren’t biased. Despite these biases, some people think it’s better to have machines deciding, rather than live editors. At Daily Maverick, the editor-in-chief, Branko Brkic, and his team will choose certain stories over others. Their choices have certain biases that will affect what we see and what we don’t. In news terms, they suggest what is important and newsworthy. These are valid issues and are true of all journalists and indeed people (#journalistsarepeopletoo). The biases that inform this article are informed by the organisation we work for and the Constitution. We seek to build and deepen our democracy and human rights. It colours all of our work and indeed our approach. Knowing it means you can take us on, but we are open and transparent about it. Our public broadcaster has similar biases, informed by people, policies, resources and its role as public broadcaster. Credible news media, for the most part, are at least clear and transparent about their biases. Social media platforms, broadly speaking, are not. But there is another critical difference. Unlike a news editor who chooses what news to cover, social media platforms use automated decision-making to shape what each and every one of us sees. So, imagine this. If we take a newspaper, like Daily Maverick 168, and give it to five people, they all have access to the same stories, layout etc. They are seeing and being exposed to the same thing. When it comes to social media, the same five people will see different things depending on a range of factors, from where they live, their age, their gender, their shopping habits, their friends, likes, their search terms and of course their politics. Some content might be similar, for example if you are in a family group you might all see the same posts and images, but just about everything else is tailored to you. There are a number of consequences to the approach taken by social media platforms. On one side they will assure us that we get the content we are interested in. The counter to this is that it also tends to help us exist in our echo chamber. We see images and views from others who share our views and ideas. If you like conservative politics you are most likely to be exposed to like-minded people and content. If you are a radical fundamentalist it is unlikely that you will see content that asserts a rights-based approach. To a degree, there is nothing wrong with seeing content that matches your world-view, it means you can share things that others can understand and identify with. Conversely, it also limits your exposure to different views and thinking. So, what’s this got to do with disinformation? If for example you have conservative views about migration, or if you have lost your job, you may well see posts about those things and if they are framed in line with the other elements in your echo chamber they are more likely to resonate. A post from a person whom you follow and whom you may know will be more likely to be read and believed. A key element of disinformation beyond the content of the post then is that it will appear framed to suit your echo chamber. There is another element to disinformation, and that is the networks, but we will unpack that next week. For this week, we have a task for you. See if you can start to delineate your echo chamber. Be conscious of whose posts you see, which tweets. Ask yourself whose views you are seeing and whose views you are not. An easy way to get into this exercise is to look at how many women and how many men you see and hear from. Then, as you start to think about that, ask who they are, who has authority or gravitas and who doesn’t. Once you get used to that, start to look at what you are seeing and when you see a post that makes you feel, “Yes, yes that’s how I feel!” stop and ask yourself what it was about that post or tweet that helped you feel that. Knowing who and what is likely to be in your echo chamber can help you escape it sometimes, and also help you to be aware of your own biases. That might not sound important, but it is a critical weapon to protect yourself from disinformation. As you seek to delineate your echo chamber, if you see something that you think is disinformation, report it to Real411. DM Please note you must be a Maverick Insider to comment. Sign up here or sign in if you are already an Insider. Everybody has an opinion but not everyone has the knowledge and the experience to contribute meaningfully to a discussion. That’s what we want from our members. Help us learn with your expertise and insights on articles that we publish. We encourage different, respectful viewpoints to further our understanding of the world. View our comments policy here. No Comments, yet