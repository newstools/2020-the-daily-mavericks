Not only are persons with disabilities ‘zoomed out’ online at present, but also when trying to stay up to date with Covid-19 related television broadcasts, says the writer. (Photo: Flickr / Durley Beachbum) The Covid-19 lockdown forces people to rely on technology for almost all communication. In some cases, people spend hours on screens, fatigued by the intensified digital interaction or frustrated by audio and visual distortions if they don’t have fibre connections. For people with hearing impairments, communicating with work colleagues, friends and family has become a lot more difficult. The Covid-19 restrictions have greatly challenged our “normal” way of life. People are worried about their income, businesses, jobs, food for their families and their futures. The fortunate ones are working from home using modern technologies such as Microsoft Teams, Zoom, Skype, Google Meet, Whereby, and similar internet-based video communication platforms to get through the demands of the working day. Many already had some of this technology at home or were equipped by their employers to function from home. Being enabled to keep in touch with colleagues and family and friends, locally and internationally, also goes a long way to relieve the mental tedium and loneliness of lockdown. In the first weeks of lockdown, people quickly encountered the challenges of staring at a screen all day while hosting or participating in video meetings – the exhaustion, headaches and blurred vision that comes with it. Others lacked sufficient bandwidth on ADSL and 4G to enjoy the full benefits of these platforms, so their communication was riddled with audio and video distortions and background noise. A good fibre connection seems to be the best option, but it is not always affordable. Hearing impaired and deaf persons using these platforms in the workplace are facing additional challenges. It seems that the voice recognition software is not yet sufficiently accurate and reliable to support them during meetings. Accessibility features, including audio and video enhancement and captioning/subtitling, often don’t work optimally. Captions provide the audio dialogue in text format but include other background noise, such as “wind blowing” or “leaves rustling”. Subtitles provide a text format of the dialogue only and don’t indicate the background noise. Both can be closed or open. Open captions/subtitles cannot be turned on or off by the user. They are permanently on the screen for the duration of the broadcast or meeting. Closed captions can be turned off by the user if the decoder or computer software allows this. Most of these internet meeting platforms provide closed-captioning/subtitling and other accessibility features. However, most also require either a business package or an extra premium. Zoom provides for closed captioning/subtitling, but the big drawback and extra expense is that it requires one of the participants to type up the conversation in real-time. This requires skill and it is expensive to hire a qualified note-taker or stenographer. The very nature of these apps might make them suitable for phone users participating in individual face-to-face conversations, but not for large meetings, which require a computer. If you are using a portable T-coil system or Bluetooth streamer connected to your phone or computer, this can override the speakers and thus the apps will not work as intended. Another option is to use web-based voice recognition software in conjunction with your favourite platform. Apps are seemingly available for some computers and smartphones. This procedure is cumbersome and works in two basic ways. One is to install web-based speech recognition tools to work with Zoom, such as Web Captioner or Otter on your computer. Both these display the speech on a separate web page, meaning one must move from looking at Zoom to looking at the text display on another page. Both seem to be dependent on the quality of the computer speakers and the sound that is played through these speakers. They do not directly link into Zoom or any other video platform. Those that do directly link into Zoom and other platforms are virtually incoherent, with no idea of who is speaking and insufficient text to understand the conversation. The second is even more cumbersome and involves installing automatic speech recognition applications on your smartphone. Most apps are compatible with Android phones but not always with iPhones. Apps include Live Transcribe, Otter, and Ada Dictation. The drawback with most of these apps is, again, that they are not part of the video platform but must use the computer speakers to obtain and analyse the speech. The implication is that these apps and the web-based speech recognition links depend on your computer speakers, their quality and location, so you can watch the video conference and also the subtitles on your phone or another window on the computer screen. This arrangement is in itself problematic. These options are also susceptible to background noise within your immediate environment. Unlike the video platforms, you cannot mute your device’s microphone, or you will lose the video subtitling. The very nature of these apps might make them suitable for phone users participating in individual face-to-face conversations, but not for large meetings, which require a computer. If you are using a portable T-coil system or Bluetooth streamer connected to your phone or computer, this can override the speakers and thus the apps will not work as intended. With the help of members of the National Council of and for Persons with Disabilities, I recently tested out several platforms with hearing impaired and deaf persons, and found that the subtitling on Google Meet was far more accurate than those of other platforms. We used the free version of Google Meet, which is limited to between 50 and 100 participants but only allows you to view 16 participants. The Enterprise package has greater visual coverage but comes at an additional premium. Most hearing-impaired or deaf South Africans cannot use or even understand SASL. Captioning or subtitling would benefit the hearing impaired, many of the deaf and also those who do not consider themselves hearing impaired but might struggle with accessing the spoken content of the news broadcasts. Our first concern was the quality and comprehension of the subtitling and, despite some inability to recognise certain South African words, particularly people and place names, we found Google Meet to provide the most accurate closed subtitling currently available. Participants could engage without any other devices or the need to split screens, and individuals, not only the host, could turn the subtitles on and off as they preferred. Not only are persons with disabilities “zoomed out” online at present, but also when trying to stay up to date with Covid-19 related television broadcasts. Most public and private enterprises in South Africa have dismally failed to cater to the needs of persons with disabilities. In this respect, the national broadcaster, SABC, provides a South African Sign Language (SASL) interpreter for the news and notably the presidential addresses related to Covid-19. However, and despite Directive 1.4.2 of the 2015 White Paper on the Rights of Persons with Disabilities and particularly Paragraph 6.1.1.4 on Access to Information and Communication, which demands complete subtitling of all news content for local television stations, this remains non-existent in practice. Five years later and we still have no captioning/subtitling on our local news and during presidential speeches to the nation. Most hearing-impaired or deaf South Africans cannot use or even understand SASL. Captioning or subtitling would benefit the hearing impaired, many of the deaf and also those who do not consider themselves hearing impaired but might struggle with accessing the spoken content of the news broadcasts. In the United Kingdom, the Office of Communications (Ofcom), the regulatory body for UK television broadcasting, undertook a study to determine the use of subtitling by viewers. Of the 7.5 million people who used closed captions/subtitling, only 1.5 million were hearing impaired or deaf. The study illustrated that second-language English speakers also benefited from the subtitling option. Others stated that they could engage better with the dialogue content as a result of the use of subtitles. Let’s bear in mind that disabilities, and especially hearing and visual impairment, increase with age. Thus, closed captioning or subtitling is necessary and helpful to many South Africans, not only during the lockdown, but will remain so afterwards. To ensure the inclusion of all South Africans in comprehending the implications of Covid-19, along with the strategies government is undertaking to reduce its impact, the government must immediately ensure open captions/subtitles of all news broadcasts on all local channels. The refinement of the accessibility features of existing video platforms and open captioning of news broadcasts would be a great step towards accommodating the deaf and the hearing impaired and will likely benefit many others. DM Tim GB Hart is a senior research manager in the Developmental, Capable and Ethical State research division of the Human Sciences Research Council. Please note you must be a Maverick Insider to comment. Sign up here or sign in if you are already an Insider.