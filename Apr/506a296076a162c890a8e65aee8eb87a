Image by Pete Linforth from Pixabay This article was first published by Roving Reporters here It can be difficult to understand the subtle nuances science communicators use in their articles. Scientists too can be swayed by emotion in their haste to share their potentially groundbreaking discoveries. The speed at which scientific papers are being published could be partly to blame for the deluge of information overwhelming us. Reuters labelled this phenomenon “Speed Science”. It found that at least 153 studies encompassing many scientific areas had been posted or published since the start of the Covid-19 outbreak. Some 675 researchers were responsible for this prolific output. In stark contrast, during the SARS outbreak in 2003, fewer than half this number of studies were published in double the time. The World Economic Forum was critical of the phenomenon. “While speedy scientific analysis is highly useful if it’s good, flawed or misleading science can sow panic and may make a disease epidemic worse by prompting false policy moves or encouraging risky behaviour,” it said. Under ideal circumstances, researchers submit their work to a process called peer review. Peer reviewing is not for the fainthearted. A cautionary note to a peer reviewer states, “You’re responsible for protecting the public from false findings and research flaws, while at the same time helping to uncover legitimate breakthroughs.” Peer review has a long history. It has been with us since the 9th century. While peer review helps maintain research standards, some believe it suppresses innovation and creativity. It may also, critics charge, be subject to bias, and even fraud. This could account for the rise of the preprint websites such as arXiv, medRxiv, and bioRxiv. Preprint can serve an important function. It lets researchers share results and get early feedback from peers. But it has its drawbacks, as the Reuters analysis indicated. Some sites, like medRxiv, do include a disclaimer along the lines of: “Preprints are preliminary reports of work that have not been certified by peer review. They should not be relied on to guide clinical practice or health-related behaviour and should not be reported in news media as established information.” Luckily, there’s an industry devoted to fact-checking that can help make sense of the chaos. There has been a substantial rise in the number of fact-checking organisations since 2010. One of these organisations is Retraction Watch. It tracks retractions of scientific publications and highlights incidences of scientific misconduct. The parent organisation of Retraction Watch is the Centre for Scientific Integrity. Its aim is to “promote transparency and integrity in science and scientific publishing, and to disseminate best practices and increase efficiency in science”. Other fact checking sites include FACTCHECK.org, run by the Annenberg Foundation, The International Fact-Checking Network (ICFN), run by the Poynter Institute, AfricaCheck, Full Fact, and UNDARK. Another organisation, Metafact, says, “Some questions are just too important to ask the internet.” Its website states: “Technology now enables agendas, spin and misinformation to go viral with greater velocity and impact than ever before.” And that false news often spreads up to six times faster than the truth. To compare the speed of false news versus the spread of truth, Soroush Vosoughi, Deb Roy, and Sinan Aral used a data set of “rumour cascades” on Twitter in the period 2006 -2017. A rumour cascade starts on Twitter when a tweeter opines about a topic in a tweet. The tweet could include written text, photos, or links to articles online. They found that 126,000 rumours were spread by about 3 million people. Surprisingly, it was people who spread the rumours, and not bots. Bot accounts are those which generate retweets without any human involvement. Also, the top 1% of false news cascades, spread to between 1,000 and 100,000 people. The truth, on the other hand, reached barely 1,000 people, and the spread of truth was much slower compared to the spread of falsehood. Researchers attributed the quick spread of false information to the emotional reaction induced by the message as well as the novelty factor. Another study, by the Pew Research Centre, ascribed two-thirds of tweeted links to popular websites as being posted by automated accounts – not human beings. This study was carried out over a shorter period from July 27 to September 11, 2017. If you feel like it may be too much trouble to access these sites, or if you’re suspecting a bot may have retweeted a popular article, you could ask yourself a series of five questions as posted by Scholastic HEADS UP. It should give some clarity, and reduce that incessant hum from the often contradictory opinions. DM Fatima Khan has a background in laboratory research and education. She enrolled on Roving Reporters’ environmental journalism training programme in 2019 and is now Roving Reporters’ lead researcher and associate editor. Please note you must be a Maverick Insider to comment. Sign up here or sign in if you are already an Insider.