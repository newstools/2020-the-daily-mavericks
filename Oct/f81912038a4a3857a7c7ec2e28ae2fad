(Photo: Needpix.com) Week20: Weekly trends – stoking xenophobia, deepening ignorance – pack mentality Through Real411, Media Monitoring Africa has been tracking disinformation trends on digital platforms since the end of March 2020. Using the Real411 platform we have analysed disinformation trends which have largely focused on Covid-19. To date, 865 complaints have been submitted to the platform, 97% of which have been assessed by experts, and action taken. Complaint #899  The first few weeks of October saw a flurry of complaints. They tended to focus on two areas, Covid-19 denialists (those who deny how serious it is; that masks, lockdowns and other forms of limiting spread don’t work) and xenophobic spreaders. The word cloud shows the most common complaints submitted by topic. It is clear that complaints relating to Covid-19, xenophobia, racism, and conspiracy theories have dominated the type of content submitted to the platform.  WARNING: This week there is some strong language. We have used examples (subject to minor word changes) from actual engagements with disinformers. Below are a few examples of complaints submitted over the week 12-18 October, that do not necessarily constitute disinformation, but are typical of racist and xenophobic content. Complaint #912  Complaint #899 and #912 are both simple examples of harmful content that is racist and xenophobic that has been circulating on Twitter. We have looked at how disinformation works, and what makes it powerful. We have also looked at xenophobia and Covid-19 denialists. This week we look at how, despite these being seemingly quite different, the techniques they use are surprisingly similar, not just the disinformation but how they respond. Likes, mentions and retweets help surface stuff that is useful, and the algorithms ensure you see more things that have greater engagement. While this works to help see things that might be trending, they also work for gang-like behaviours and bullying. Many of our journalists, but also public intellectuals and public officials (if they take a strong opposing position or progressive view to xenophobia or that Covid-19 is a real, dangerous epidemic) are met not just by one vile person but a gang of users. (The vileness of the insults is almost always far, far, worse for women. Women are frequently abused online for their comments, from body shaming to threats of rape or rape denialism.) This approach is particularly common when taking on not an individual, but a dodgy network. We know that social media makes it easy for anonymous users to spew abuse. In general, these can be dealt with by just blocking the users who forget they are talking to real people. Gang-like behaviour tends to be more coordinated and is a sign that if you are at the receiving end you have upset their playbook and they need to respond. Think of them more as automatons than people. In these cases, one person will reply and mention another who retweets and mentions, and as we noted in a previous analysis, they will play different roles. Collectively though, users will round on a person and hurl abuse and insults. Their game is to silence, demean and drown out any legitimate critique. One of the most common mistakes is to assume that the others are like us – that if we meet with friends or colleagues and we say something they don’t like or vice versa, we can engage and have a rational discussion and either agree to disagree or at least hear each other and reach a compromise. Disinformers don’t care. They aren’t there to engage you if you differ, but to bully and threaten you into silence. Look for these tell-tale signs: Disinformers offer no logical response to your position. Non-disinformers will show that 1 + 1 = 2, for disinformers 1 + 1 = Zebra Chicken 246 – in other words, bearing no relation at all to the preceding information.  Disinformers will draw conclusions that at best have tangential relationships. Example: “It’s xenophobic to say all Nigerians are criminals.” Disinformer: “Tell that to the victims of Nigerian traffickers, you fake rape victim.” Twisted fools: As we know disinformation is often powerful and persuasive because it has elements of truth. Disinformer groups like to take quotes selectively and use them to justify their nonsense. Example: “WHO says masks aren’t effective”. As with any emerging issue, this might have been true at one point. but certainly the evidence on WHO says otherwise: (Covid-19) advice for the public: When and how to use masks. What makes the issue frustrating is that they will use that to claim it is true of all things. Another example: News story where a person who is Nigerian has been arrested in relation to drug dealing, and suddenly “Nigerians are all criminals and drug dealers and human trafficking is in their blood.” Despite no evidence of a spike of human trafficking or kidnapping, it becomes true of all Nigerians and at a huge scale. Their logic and use of evidence is like seeing one flying fish and concluding that all fish fly. Piss in your porridge: Disinformers want to make you angry, take you down to their level and piss you off. Just in case you are unable to detect that they have the emotional maturity of a three-year-old, disinformer groups also love to use CAPITALS and shout at you!!!! Disinformers aren’t interested in debate or discussion. They want to make you angry, so they push all emotional buttons in their reply. One reason they don’t actually address any of the issues you raise is that they know it will frustrate you that your point and views are not being heard. Of course, for them, it’s a win-win. By ignoring the issue and being super-rude and abusive not only do they avoid having to show they don’t have a real answer but they are also able to frustrate you. Example: “Please help combat disinformation” Disinformers: “F$*K OFF!” Pushers: As we noted previously there are those in the online gang who will just be abusive, they will use strong language and direct insult and it will be easy to have the tweet removed. For the most part, though, Disinformers know the laws and community standards for the different platforms. They use these and skate close to the edge. They might then use language that will help incite others, but they will seldom cross the line. One reason is that the ringleaders usually have a larger following so if they get removed from the platform it makes it harder to spread their bile. It is easier, then, to sacrifice some account that has been purchased with only a few followers. So, if you see an account that crosses the line, look at how many followers they have, how long they have been active; almost always they will also have some made-up name and no profile picture that can be easily identified. Disinformation, racist speech, hate speech and xenophobia existed long before the internet, digital platforms and social media. What we are seeing now is the exponentially increasing size of audience that this content reaches. One of the most important concepts to internalise is that when you come across content that incites certain emotions whether fear, anger, anxiety or hurt, it is critical that you stop and think before you engage or share the content. Also, it can be tempting to engage the disinformers – but unless you respond with evidence that is unemotionally charged you will play right into their hands. Even then prepare yourself for a lot of time spent on trying to reason with someone who just doesn’t care. The key is to try to be the adult, respond with dignity and evidence. DM Please note you must be a Maverick Insider to comment. Sign up here or sign in if you are already an Insider. Everybody has an opinion but not everyone has the knowledge and the experience to contribute meaningfully to a discussion. That’s what we want from our members. Help us learn with your expertise and insights on articles that we publish. We encourage different, respectful viewpoints to further our understanding of the world. View our comments policy here. No Comments, yet